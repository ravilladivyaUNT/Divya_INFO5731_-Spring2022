{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravilladivyaUNT/Divya_INFO5731_-Spring2022/blob/main/INFO5731_Assignment_Two_1_(1)_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [Apple iPhone 11](https://www.amazon.com/Apple-iPhone-11-64GB-Unlocked/dp/B07ZPKF8RG/ref=sr_1_13?dchild=1&keywords=iphone+12&qid=1631721363&sr=8-13) on amazon.\n",
        "\n",
        "(2) Collect the top 10000 User Reviews of the film [Shang-Chi and the Legend of the Ten Rings](https://www.imdb.com/title/tt9376612/reviews?ref_=tt_sa_3) from IMDB.\n",
        "\n",
        "(3) Collect all the reviews of the top 100 most popular software from [G2](https://www.g2.com/) or [Capterra](https://www.capterra.com/)\n",
        "\n",
        "(4) Collect the abstracts of the top 10000 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the [Densho Digital Repository](https://ddr.densho.org/narrators/).\n",
        "\n",
        "(6) Collect the top 10000 tweets by using hashtag [\"#blacklivesmatter\"](https://twitter.com/hashtag/blacklivesmatter) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, openpyxl\n",
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!apt-get update\n",
        "from bs4 import BeautifulSoup as bs\n",
        "!apt install chromium-chromedriver\n",
        "import urllib.request as req\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import pandas as pd\n",
        "import time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HKRYC72vl8aV",
        "outputId": "ad4abe3e-5e68-4336-db20-fdb5b99bbde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Using cached urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.20.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (36.0.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.25.11\n",
            "    Uninstalling urllib3-1.25.11:\n",
            "      Successfully uninstalled urllib3-1.25.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.26.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 256 kB in 2s (122 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (97.0.4692.71-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 69 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "from selenium import webdriver \n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ],
      "metadata": {
        "id": "-_MXBHF-l4nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [] \n",
        "reviews= []\n",
        "link = 'https://www.imdb.com/title/tt9376612/reviews?ref_=tt_sa_3'\n",
        "d = webdriver.Chrome('chromedriver',options=options) #creating a driver path\n",
        "d.get(link)\n",
        "for num in range(43):         \n",
        "  d.find_element_by_class_name(\"ipl-load-more__button\").click() \n",
        "  time.sleep(5)\n",
        "  LTitle = d.find_elements(By.CLASS_NAME, \"title\") #Using Find_elements to get titles of the movie\n",
        "  LReviews = d.find_elements(By.CLASS_NAME, \"text\") #Using Find_elements to get reviews of the movie\n",
        "  \n",
        "for e, r in zip(LTitle, LReviews):            # appending all reviews and titles into the empty arrays\n",
        "      titles.append((e.text).replace('\\n',''))\n",
        "      reviews.append(r.text)\n",
        "      \n",
        "data = pd.DataFrame(list(zip(titles, reviews)), columns =['Title_of_the_Review', 'Review_of_the_movie'])\n",
        "\n",
        "print(\"Length of data frame is\",len(data))\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0YyGAGZPx7Y",
        "outputId": "6af8c298-5c42-41b6-824b-524107f955d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: find_element_by_class_name is deprecated. Please use find_element(by=By.CLASS_NAME, value=name) instead\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1099\n",
            "                    Title_of_the_Review                                Review_of_the_movie\n",
            "0                       A visual feast.                                                   \n",
            "1                            Next Phase                                                   \n",
            "2                               Bus Boy                                                   \n",
            "3                                  Wow!  I was not expecting that, I had visions of a f...\n",
            "4                Precious ... ten times  Of course I am just riffing off, teasing and m...\n",
            "...                                 ...                                                ...\n",
            "1094            Very pleasing to watch.  Most beautiful Marvel movie there's ever been....\n",
            "1095                          Loved it.  It's a nice classic Marvel movie with great im...\n",
            "1096                This is incredible!                                                   \n",
            "1097           More than a marvel movie  How do I start, this movie first is full of ex...\n",
            "1098  Was this Mulan or a Marvel flick?                                                   \n",
            "\n",
            "[1099 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import nltk.corpus\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTwp1CSW-Vcv",
        "outputId": "605d5868-8fa0-46c9-c7a8-3acae2617d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "9c535896-bae5-4f0c-b257-37c3b6b8190f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    Title_of_the_Review                                Review_of_the_movie\n",
            "3                                                  Wow!  I was not expecting that, I had visions of a f...\n",
            "4                                Precious ... ten times  Of course I am just riffing off, teasing and m...\n",
            "7                       The best Marvel movie so far...  Having seen the trailer for the 2021 Marvel ac...\n",
            "8                    Crouching Tiger, Hidden Superhero.  Martial arts meets the MCU in Shang-Chi and th...\n",
            "9          Very engaging plot with great visual effects  I find this film very engaging from start to f...\n",
            "...                                                 ...                                                ...\n",
            "1091  Decent superhero flick, but shallow plot and w...  It's a decent fun adventure movie, and it is v...\n",
            "1093                                           AMAZING!  HUGE step-up from Black Widow. This movie made...\n",
            "1094                            Very pleasing to watch.  Most beautiful Marvel movie there's ever been....\n",
            "1095                                          Loved it.  It's a nice classic Marvel movie with great im...\n",
            "1097                           More than a marvel movie  How do I start, this movie first is full of ex...\n",
            "\n",
            "[928 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df=data\n",
        "df=df[df[\"Review_of_the_movie\"]!= \"\"] #Removing null review\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GwLZrFoVEIPe",
        "outputId": "78536bf1-4e33-43e0-8855-fe56b33ef36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d91098ec-a431-4919-a043-1961e6365820\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title_of_the_Review</th>\n",
              "      <th>Review_of_the_movie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>I was not expecting that, I had visions of a f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Precious ... ten times</td>\n",
              "      <td>Of course I am just riffing off, teasing and m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The best Marvel movie so far...</td>\n",
              "      <td>Having seen the trailer for the 2021 Marvel ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Crouching Tiger, Hidden Superhero.</td>\n",
              "      <td>Martial arts meets the MCU in Shang-Chi and th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Very engaging plot with great visual effects</td>\n",
              "      <td>I find this film very engaging from start to f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>Decent superhero flick, but shallow plot and w...</td>\n",
              "      <td>It's a decent fun adventure movie, and it is v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>AMAZING!</td>\n",
              "      <td>HUGE step-up from Black Widow. This movie made...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>Very pleasing to watch.</td>\n",
              "      <td>Most beautiful Marvel movie there's ever been....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>Loved it.</td>\n",
              "      <td>It's a nice classic Marvel movie with great im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>More than a marvel movie</td>\n",
              "      <td>How do I start, this movie first is full of ex...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>928 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d91098ec-a431-4919-a043-1961e6365820')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d91098ec-a431-4919-a043-1961e6365820 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d91098ec-a431-4919-a043-1961e6365820');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                   Title_of_the_Review                                Review_of_the_movie\n",
              "0                                                 Wow!  I was not expecting that, I had visions of a f...\n",
              "1                               Precious ... ten times  Of course I am just riffing off, teasing and m...\n",
              "2                      The best Marvel movie so far...  Having seen the trailer for the 2021 Marvel ac...\n",
              "3                   Crouching Tiger, Hidden Superhero.  Martial arts meets the MCU in Shang-Chi and th...\n",
              "4         Very engaging plot with great visual effects  I find this film very engaging from start to f...\n",
              "..                                                 ...                                                ...\n",
              "923  Decent superhero flick, but shallow plot and w...  It's a decent fun adventure movie, and it is v...\n",
              "924                                           AMAZING!  HUGE step-up from Black Widow. This movie made...\n",
              "925                            Very pleasing to watch.  Most beautiful Marvel movie there's ever been....\n",
              "926                                          Loved it.  It's a nice classic Marvel movie with great im...\n",
              "927                           More than a marvel movie  How do I start, this movie first is full of ex...\n",
              "\n",
              "[928 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stpwordlist = stopwords.words('english')\n",
        "snow_stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def clean(df):\n",
        "    #Remove noise, such as special characters and punctuations.\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"Review_of_the_movie\"].apply(lambda ele: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", ele))\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].apply(lambda ele: re.sub(r\"\\d+\", \"\", ele))   #Remove numbers\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].apply(lambda string: ' '.join([w for w in string.split() if w not in (stpwordlist)])) #Remove stopwords by using the stopwords list\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].str.lower()  #Lowercase all texts\n",
        "    df.loc[:,[\"tokens\"]] = df[\"clean_txt\"].apply(lambda x: word_tokenize(x))  #word tokenize\n",
        "    def word_stemmer(text):\n",
        "      stem_text = [snow_stemmer.stem(i) for i in text]\n",
        "      return stem_text\n",
        "    df.loc[:,['text_stem']] = df[\"tokens\"].apply(lambda x: word_stemmer(x))  #Stemming\n",
        "    def word_lemmatizer(text):\n",
        "      lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
        "      return lem_text\n",
        "    df.loc[:,['text_lem']] = df[\"tokens\"].apply(lambda x: word_lemmatizer(x))  # Lemmatization\n",
        "    return df\n",
        "c=clean(df)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8T6Bi6M-pG3",
        "outputId": "2f121dff-2f5e-4eff-8b3c-4090afbd47f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Title_of_the_Review  ...                                           text_lem\n",
            "0                                                 Wow!  ...  [i, expecting, i, vision, film, along, line, s...\n",
            "1                               Precious ... ten times  ...  [of, course, i, riffing, teasing, making, fun,...\n",
            "2                      The best Marvel movie so far...  ...  [having, seen, trailer, marvel, action, movie,...\n",
            "3                   Crouching Tiger, Hidden Superhero.  ...  [martial, art, meet, mcu, shangchi, legend, te...\n",
            "4         Very engaging plot with great visual effects  ...  [i, find, film, engaging, start, finish, i, co...\n",
            "..                                                 ...  ...                                                ...\n",
            "923  Decent superhero flick, but shallow plot and w...  ...  [it, decent, fun, adventure, movie, much, run,...\n",
            "924                                           AMAZING!  ...  [huge, stepup, black, widow, this, movie, made...\n",
            "925                            Very pleasing to watch.  ...  [most, beautiful, marvel, movie, there, ever, ...\n",
            "926                                          Loved it.  ...  [it, nice, classic, marvel, movie, great, imag...\n",
            "927                           More than a marvel movie  ...  [how, i, start, movie, first, full, excitement...\n",
            "\n",
            "[928 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('clean.csv')"
      ],
      "metadata": {
        "id": "0SHcZsMPFfdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "%tensorflow_version 1.x\n",
        "!pip install benepar\n",
        "import benepar\n",
        "benepar.download('benepar_en2')\n",
        "from benepar.spacy_plugin import BeneparComponent\n",
        "benepar.download('benepar_en3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s93MVUAXCyr-",
        "outputId": "423200d7-8818-4777-bb16-28161c4c55ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: benepar in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: transformers[tokenizers,torch]>=4.2.2 in /usr/local/lib/python3.7/dist-packages (from benepar) (4.16.2)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.7/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from benepar) (0.1.96)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.7/dist-packages (from benepar) (2.2.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from benepar) (3.17.3)\n",
            "Requirement already satisfied: torch-struct>=0.5 in /usr/local/lib/python3.7/dist-packages (from benepar) (0.5)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from benepar) (0.11.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from benepar) (1.10.0+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2->benepar) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.21.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.9.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.9->benepar) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.9->benepar) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.9->benepar) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2021.10.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (0.0.47)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[tokenizers,torch]>=4.2.2->benepar) (3.0.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (1.1.0)\n",
            "[nltk_data] Error loading benepar_en2: Package 'benepar_en2' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
            "[nltk_data]   Package benepar_en3 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQKnPjPDHJHr",
        "outputId": "14d7d35a-15c7-4b3e-95d5-df2c58e1cc99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Title_of_the_Review  ...                                         pos_tagged\n",
            "0                                                 Wow!  ...  [(i, NN), (expecting, VBG), (i, JJ), (visions,...\n",
            "1                               Precious ... ten times  ...  [(of, IN), (course, NN), (i, NN), (riffing, VB...\n",
            "2                      The best Marvel movie so far...  ...  [(having, VBG), (seen, VBN), (trailer, NN), (m...\n",
            "3                   Crouching Tiger, Hidden Superhero.  ...  [(martial, JJ), (arts, NNS), (meets, NNS), (mc...\n",
            "4         Very engaging plot with great visual effects  ...  [(i, JJ), (find, VBP), (film, NN), (engaging, ...\n",
            "..                                                 ...  ...                                                ...\n",
            "923  Decent superhero flick, but shallow plot and w...  ...  [(its, PRP$), (decent, JJ), (fun, NN), (advent...\n",
            "924                                           AMAZING!  ...  [(huge, JJ), (stepup, NN), (black, JJ), (widow...\n",
            "925                            Very pleasing to watch.  ...  [(most, RBS), (beautiful, JJ), (marvel, NN), (...\n",
            "926                                          Loved it.  ...  [(its, PRP$), (nice, JJ), (classic, JJ), (marv...\n",
            "927                           More than a marvel movie  ...  [(how, WRB), (i, JJ), (start, VBP), (movie, NN...\n",
            "\n",
            "[928 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "def pos_tagger(text):\n",
        "    pos_tagged = nltk.pos_tag(text)\n",
        "    return pos_tagged\n",
        "df.loc[:,['pos_tagged']]= df['tokens'].apply(lambda x: pos_tagger(x))\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def spcy(text):\n",
        "  for t in text:\n",
        "    for token in nlp(t):\n",
        "      return [token.text, '-',token.pos_,'-',token.tag_]\n",
        "df['pos']=df['tokens'].apply(lambda x: spcy(x))\n",
        "print(df['pos'].head())\n",
        "print(len(df['pos']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Ax9mVmITVx",
        "outputId": "f0557e05-05a6-4315-fe65-6010a3a86f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         [i, -, PRON, -, PRP]\n",
            "1          [of, -, ADP, -, IN]\n",
            "2    [having, -, VERB, -, VBG]\n",
            "3     [martial, -, ADJ, -, JJ]\n",
            "4         [i, -, PRON, -, PRP]\n",
            "Name: pos, dtype: object\n",
            "928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependency parsing is the procedure of examining the grammatical form of the text  based on the dependencies among the key words in a sentence.\n"
      ],
      "metadata": {
        "id": "ovo-u3iT2F3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependency Parsing\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "def depen(text):\n",
        "  for t in text[:100]:\n",
        "    for token in nlp(t):\n",
        "      return [token.text,'-',token.dep_,'-',token.head.text]\n",
        "df['dep']=df['tokens'].apply(lambda x: depen(x))\n",
        "print(df['dep'].head())\n",
        "print(len(df['dep']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LspMAonEQjP5",
        "outputId": "57e5c595-c3d9-4f3c-e754-74904cb68239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                [i, -, ROOT, -, i]\n",
            "1              [of, -, ROOT, -, of]\n",
            "2      [having, -, ROOT, -, having]\n",
            "3    [martial, -, ROOT, -, martial]\n",
            "4                [i, -, ROOT, -, i]\n",
            "Name: dep, dtype: object\n",
            "928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constituency Parsing is the method of evaluating the sentences by splitting  it into sub-phrases."
      ],
      "metadata": {
        "id": "KA1KG3kl4D0F"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "INFO5731_Assignment_Two_1_(1)_(2).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}