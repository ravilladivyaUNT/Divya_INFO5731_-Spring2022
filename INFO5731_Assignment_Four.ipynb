{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravilladivyaUNT/Divya_INFO5731_-Spring2022/blob/main/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA and LSA. The following information should be reported:\n",
        "\n",
        "(1) Features (top n-gram phrases) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4B_U9GPRVbX",
        "outputId": "f5fd15e7-6f94-4a59-f0db-98c94ecec881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "outputId": "259fae70-45a5-4fca-8532-7c19b7a3209d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\maganti\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyldavis in c:\\users\\maganti\\anaconda3\\lib\\site-packages (3.3.1)\n",
            "Requirement already satisfied: sklearn in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (0.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (1.0.2)\n",
            "Requirement already satisfied: gensim in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (4.1.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (1.3.4)\n",
            "Requirement already satisfied: funcy in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (1.17)\n",
            "Requirement already satisfied: scipy in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (1.7.1)\n",
            "Requirement already satisfied: numexpr in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (2.7.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (1.20.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (2.11.3)\n",
            "Requirement already satisfied: future in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (0.18.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pyldavis) (60.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyldavis) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from gensim->pyldavis) (5.2.1)\n",
            "Requirement already satisfied: Cython==0.29.23 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from gensim->pyldavis) (0.29.23)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from jinja2->pyldavis) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from scikit-learn->pyldavis) (2.2.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyldavis) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(module.__version__) < minver:\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(module.__version__) < minver:\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(module.__version__) < minver:\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(module.__version__) < minver:\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(module.__version__) < minver:\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\maganti\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['amazing', 'movie', 'marvel', 'studios', 'hyped', 'movie', 'since', 'first', 'teaser', 'movie', 'actually', 'exceedes', 'expectations', 'marvel', 'showing', 'marvelous', 'magic', 'since', 'ironman', 'shangchi', 'another', 'diamond', 'crown', 'end', 'mcus', 'phase', 'fans', 'eagerly', 'waiting', 'big', 'movie', 'black', 'widow', 'mark', 'eternals', 'also', 'disappointed', 'majority', 'fans', 'changchi', 'filled', 'gap', 'action', 'scenes', 'fresh', 'engaging', 'martial', 'arts', 'combined', 'chinese', 'mythological', 'powers', 'makes', 'action', 'scenes', 'interesting', 'character', 'arc', 'story', 'building', 'satisfying', 'rushed', 'slow', 'paced', 'whole', 'movie', 'engaging', 'till', 'end', 'would', 'love', 'see', 'another', 'movie', 'franchise']]\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "!pip install pyldavis\n",
        "import pyLDAvis\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/data.csv\")\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "reviews = list(data['clean_text'].values)\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "reviews_words = list(sent_to_words(reviews))\n",
        "\n",
        "print(reviews_words[:1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAYPqqdbRBJg"
      },
      "source": [
        "# 1.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4akFx3oRBJi",
        "outputId": "bef873f4-fa68-4cfb-97a4-cf4edcca0f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['amazing', 'movie', 'marvel', 'studios', 'hyped', 'movie', 'since', 'first', 'teaser', 'movie', 'actually', 'exceedes', 'expectations', 'marvel', 'showing', 'marvelous', 'magic', 'since', 'ironman', 'shangchi', 'another', 'diamond', 'crown', 'end', 'mcus', 'phase', 'fans', 'eagerly', 'waiting', 'big', 'movie', 'black_widow', 'mark', 'eternals', 'also', 'disappointed', 'majority', 'fans', 'changchi', 'filled', 'gap', 'action', 'scenes', 'fresh', 'engaging', 'martial_arts', 'combined', 'chinese', 'mythological', 'powers', 'makes', 'action', 'scenes', 'interesting', 'character', 'arc', 'story', 'building', 'satisfying', 'rushed', 'slow', 'paced', 'whole', 'movie', 'engaging', 'till', 'end', 'would', 'love', 'see', 'another', 'movie', 'franchise']\n"
          ]
        }
      ],
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(reviews_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[reviews_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[reviews_words[0]]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eefVDn_RBJl"
      },
      "source": [
        ". We used bigrmas and trigrams phrases from the corpus as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E2-ImG4RBJn",
        "outputId": "2e15e7ca-ff6f-40cb-dc38-e9b279e3069c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['amazing', 'movie', 'marvel', 'studio', 'hype', 'movie', 'first', 'teaser', 'movie', 'actually', 'exceed', 'expectation', 'marvel', 'show', 'marvelous', 'magic', 'ironman', 'shangchi', 'diamond', 'crown', 'end', 'mcus', 'phase', 'fan', 'eagerly', 'wait', 'big', 'movie', 'mark', 'eternal', 'also', 'disappoint', 'majority', 'fan', 'changchi', 'fill', 'gap', 'action', 'scene', 'fresh', 'engage', 'martial_art', 'combine', 'chinese', 'mythological', 'power', 'make', 'action', 'scene', 'interesting', 'character', 'arc', 'story', 'building', 'satisfy', 'rush', 'slow', 'pace', 'whole', 'movie', 'engage', 'end', 'love', 'see', 'movie', 'franchise']]\n"
          ]
        }
      ],
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "\n",
        "\n",
        "reviews_words_nostops = remove_stopwords(reviews_words)\n",
        "\n",
        "# Form Bigrams\n",
        "reviews_words_bigrams = make_bigrams(reviews_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "reviews_lemmatized = lemmatization(reviews_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(reviews_lemmatized[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6rp61w9RBJr"
      },
      "source": [
        "# 2.) Top 10 Clusters for topic modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMUEomcHRBJt",
        "outputId": "670be036-ebf5-4d0c-b606-6c1bbbb96ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 6), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1)]]\n",
            "\n",
            "[(0,\n",
            "  '0.030*\"stand\" + 0.022*\"visually_stunne\" + 0.020*\"highly\" + 0.017*\"head\" + '\n",
            "  '0.016*\"alone\" + 0.015*\"basis\" + 0.015*\"screenplay\" + 0.015*\"aside\" + '\n",
            "  '0.007*\"logic\" + 0.007*\"detract\"'),\n",
            " (1,\n",
            "  '0.028*\"man\" + 0.015*\"master\" + 0.014*\"event\" + 0.013*\"cinematic\" + '\n",
            "  '0.013*\"product\" + 0.011*\"heavy\" + 0.010*\"ancient\" + 0.009*\"evil\" + '\n",
            "  '0.009*\"death\" + 0.009*\"sean\"'),\n",
            " (2,\n",
            "  '0.015*\"place\" + 0.015*\"perhaps\" + 0.014*\"rather\" + 0.014*\"dragon\" + '\n",
            "  '0.013*\"easily\" + 0.013*\"ride\" + 0.012*\"conflict\" + 0.012*\"opinion\" + '\n",
            "  '0.012*\"genre\" + 0.012*\"mythology\"'),\n",
            " (3,\n",
            "  '0.074*\"movie\" + 0.034*\"marvel\" + 0.031*\"good\" + 0.020*\"great\" + '\n",
            "  '0.018*\"action\" + 0.017*\"story\" + 0.017*\"scene\" + 0.016*\"film\" + '\n",
            "  '0.016*\"fight\" + 0.015*\"watch\"'),\n",
            " (4,\n",
            "  '0.041*\"disappointed\" + 0.036*\"pick\" + 0.019*\"american\" + 0.014*\"coaster\" + '\n",
            "  '0.014*\"roller\" + 0.008*\"judge\" + 0.008*\"snake\" + 0.007*\"hiphoprap\" + '\n",
            "  '0.005*\"accurate\" + 0.003*\"confirm\"'),\n",
            " (5,\n",
            "  '0.030*\"film\" + 0.024*\"character\" + 0.019*\"shangchi\" + 0.014*\"new\" + '\n",
            "  '0.014*\"also\" + 0.013*\"asian\" + 0.011*\"s\" + 0.011*\"ring\" + 0.009*\"first\" + '\n",
            "  '0.008*\"leave\"'),\n",
            " (6,\n",
            "  '0.019*\"cliche\" + 0.016*\"sure\" + 0.015*\"aspect\" + 0.015*\"return\" + '\n",
            "  '0.014*\"issue\" + 0.014*\"less\" + 0.013*\"generic\" + 0.013*\"skill\" + '\n",
            "  '0.011*\"acting\" + 0.011*\"talk\"'),\n",
            " (7,\n",
            "  '0.036*\"force\" + 0.026*\"sequel\" + 0.023*\"hidden_dragon\" + 0.017*\"diverse\" + '\n",
            "  '0.014*\"dark\" + 0.014*\"masterpiece\" + 0.013*\"ragnarok\" + 0.013*\"appreciate\" '\n",
            "  '+ 0.013*\"crouching_tiger\" + 0.010*\"value\"'),\n",
            " (8,\n",
            "  '0.014*\"sight\" + 0.012*\"service\" + 0.011*\"apart\" + 0.007*\"streaming\" + '\n",
            "  '0.005*\"smash\" + 0.004*\"park\" + 0.003*\"sensation\" + 0.001*\"span\" + '\n",
            "  '0.001*\"sensory\" + 0.000*\"stigma\"'),\n",
            " (9,\n",
            "  '0.046*\"fine\" + 0.028*\"clear\" + 0.018*\"absolute\" + 0.015*\"spoiler\" + '\n",
            "  '0.014*\"requirement\" + 0.014*\"top_notch\" + 0.013*\"notice\" + 0.012*\"creative\" '\n",
            "  '+ 0.012*\"dude\" + 0.012*\"context\"')]\n"
          ]
        }
      ],
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(reviews_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = reviews_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])\n",
        "print()\n",
        "\n",
        "# builiding ldamodel\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "\n",
        "# printing the topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOyWjOkgRBJv"
      },
      "source": [
        "# 3.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ri5_DlSRBJw"
      },
      "source": [
        "We generated 10 topics.\\\n",
        "Top 10 words from each topic are as follows:\\\n",
        "Topic 0: \"stand\", \"visually_stunne\", \"highly\", \"head\", \"alone\", \"basis\", \"screenplay\", \"aside\", \"logic\", \"detract\"\\\n",
        "Topic 1: \"man\", \"master\", \"event\", \"cinematic\", \"product\", \"heavy\", \"ancient\", \"evil\", \"death\", \"sean\"\\\n",
        "Topic 2: \"place\", \"perhaps\", \"rather\", \"dragon\", \"easily\", \"ride\", \"conflict\", \"opinion\", \"genre\", \"mythology\"\\\n",
        "Topic 3: \"movie\", \"marvel\", \"good\", \"great\", \"action\", \"story\", \"scene\", \"film\", \"fight\", \"watch\"\\\n",
        "Topic 4: \"disappointed\", \"pick\", \"american\", \"coaster\", \"roller\", \"judge\", \"snake\", \"hiphoprap\", \"accurate\", \"confirm\"\\\n",
        "Topic 5: \"film\", \"character\", \"shangchi\", \"new\", \"also\", \"asian\", \"s\", \"ring\", \"first\", \"leave\"\\\n",
        "Topic 6: \"cliche\", \"sure\", \"aspect\", \"return\", \"issue\", \"less\", \"generic\", \"skill\", \"acting\", \"talk\"\\\n",
        "Topic 7: \"force\", \"sequel\", \"hidden_dragon\", \"diverse\", \"dark\", \"masterpiece\", \"ragnarok\", \"appreciate\", \"crouching_tiger\", \"value\"\\\n",
        "Topic 8: \"sight\", \"service\", \"apart\", \"streaming\", \"smash\", \"park\", \"sensation\", \"span\", \"sensory\", \"stigma\"\\\n",
        "Topc 9: \"fine\", \"clear\", \"absolute\", \"spoiler\", \"requirement\", \"top_notch\", \"notice\", \"creative\", \"dude, \"context\"\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBdgmXDVRBJy",
        "outputId": "3f1e6e19-c61a-491a-f79e-844ce4233a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -7.458231736424015\n",
            "\n",
            "Coherence Score:  0.45974788434588376\n"
          ]
        }
      ],
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=reviews_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDsQofCmRBJz",
        "outputId": "9089ab9a-1fb0-4d7f-d1a7-62f0ce7da911"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3      0.369586  0.035715       1        1  62.092371\n",
              "5      0.281956 -0.050487       2        1  25.341984\n",
              "2     -0.105851 -0.266966       3        1   4.604378\n",
              "6     -0.100846  0.204343       4        1   3.973787\n",
              "1     -0.102280  0.035375       5        1   1.423612\n",
              "9     -0.078588  0.014174       6        1   1.095768\n",
              "7     -0.078379  0.009285       7        1   0.812829\n",
              "0     -0.064215  0.006867       8        1   0.284228\n",
              "4     -0.063786  0.006702       9        1   0.263366\n",
              "8     -0.057598  0.004993      10        1   0.107677, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
              "38        movie  1641.000000  1641.000000  Default  30.0000  30.0000\n",
              "72         good   692.000000   692.000000  Default  29.0000  29.0000\n",
              "127        film   623.000000   623.000000  Default  28.0000  28.0000\n",
              "47     shangchi   171.000000   171.000000  Default  27.0000  27.0000\n",
              "8     character   411.000000   411.000000  Default  26.0000  26.0000\n",
              "...         ...          ...          ...      ...      ...      ...\n",
              "3977    frankly     0.008930     0.588596  Topic10  -8.3709   2.6455\n",
              "3979  shameless     0.008930     0.588596  Topic10  -8.3709   2.6455\n",
              "3980  umpteenth     0.008930     0.588596  Topic10  -8.3709   2.6455\n",
              "3981      weary     0.008930     0.588596  Topic10  -8.3709   2.6455\n",
              "3978  seemingly     0.008925     0.684433  Topic10  -8.3714   2.4941\n",
              "\n",
              "[430 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "55        6  0.927322  absolute\n",
              "264       1  0.998680       act\n",
              "374       4  0.973865    acting\n",
              "0         1  0.979280    action\n",
              "0         2  0.019537    action\n",
              "...     ...       ...       ...\n",
              "106       1  0.950873      well\n",
              "106       2  0.051054      well\n",
              "2080      5  1.000975      wink\n",
              "769       3  0.935865     woman\n",
              "107       1  0.998865      work\n",
              "\n",
              "[343 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 6, 3, 7, 2, 10, 8, 1, 5, 9])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyLDAvis.gensim_models\n",
        "#pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKiodNtCRBJ0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA",
        "outputId": "f32f7136-9cb6-423c-a2f1-630a33a990c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\maganti\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp/ipykernel_30708/3113960571.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data['clean_text'] = data['clean_text'].str.replace('[^a-zA-Z0-9 ]', '')\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\maganti\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>amaze movie marvel studio hype movie since fir...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ill honest marvel movie top even within marvel...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>finally fun entertain movie without garbage ho...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>goal mcu solo film sell audience new character...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>seem one marvel late marvel studio offer movie...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                         clean_text sentiment\n",
              "0            0  amaze movie marvel studio hype movie since fir...  positive\n",
              "1            1  ill honest marvel movie top even within marvel...  positive\n",
              "2            2  finally fun entertain movie without garbage ho...  negative\n",
              "3            3  goal mcu solo film sell audience new character...  negative\n",
              "4            4  seem one marvel late marvel studio offer movie...   neutral"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/data.csv\")\n",
        "\n",
        "data['clean_text'] = data['clean_text'].str.lower()\n",
        "data['sentiment'] = data['sentiment'].str.lower()\n",
        "\n",
        "# getting stopwords of english\n",
        "stopwords = stopwords.words(\"english\")\n",
        "stopwords = [re.sub('[^a-zA-Z0-9]+', '', word) for word in stopwords]\n",
        "\n",
        "# removing all special characters\n",
        "data['clean_text'] = data['clean_text'].str.replace('[^a-zA-Z0-9 ]', '')\n",
        "data['clean_text'] = data['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# applying lemmatization on the tweets\n",
        "data['clean_text'] = data['clean_text'].apply(lambda row: \" \".join(wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in row.split()))\n",
        "data['clean_text'] = data['clean_text'].apply(lambda row: \" \".join(wordnet_lemmatizer.lemmatize(word, pos=\"n\") for word in row.split()))\n",
        "data['clean_text'] = data['clean_text'].apply(lambda row: \" \".join(wordnet_lemmatizer.lemmatize(word, pos=\"a\") for word in row.split()))\n",
        "data['clean_text'] = data['clean_text'].apply(lambda row: \" \".join(wordnet_lemmatizer.lemmatize(word, pos=\"r\") for word in row.split()))\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KyqhgUZRBJ3",
        "outputId": "3f37d6a1-82e2-46e0-d8fa-1f7ce5fdcdfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "positive    864\n",
              "negative     58\n",
              "neutral      20\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSkg3cixRBJ4"
      },
      "source": [
        "# 1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QEET9VSRBJ4"
      },
      "outputs": [],
      "source": [
        "data['sentiment'] = data['sentiment'].replace({\"positive\": 0, 'negative': 1, \"neutral\": 2})\n",
        " \n",
        "X = data['clean_text']\n",
        "Y = data['sentiment']\n",
        "\n",
        "# initializing tf-idf vectorizer\n",
        "vectorizer = TfidfVectorizer(min_df = 3, ngram_range=(1, 2))\n",
        "\n",
        "# fitting the train data and generating the features\n",
        "vectorizer = vectorizer.fit(X)\n",
        "\n",
        "# transforming the data using vectorizer model that is fit using train data \n",
        "X_features = vectorizer.transform(X).toarray()\n",
        "\n",
        "# split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, Y, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db-ARZNdRBJ5"
      },
      "source": [
        "# 2.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXkU822hRBJ6"
      },
      "source": [
        "# Cross-validation on Decision Tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoclwstQRBJ6",
        "outputId": "7c3de44d-463f-4d4d-81f6-73c0527a0295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.88359788 0.87301587 0.89893617 0.90425532 0.90957447]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "dt_clr = DecisionTreeClassifier(max_depth=5)\n",
        "scores = cross_val_score(dt_clr, X_features, Y, cv=5)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BweDFA4RBJ7",
        "outputId": "bb523dd3-91c8-4082-9d2a-632e7325820c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.92       166\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.86       189\n",
            "   macro avg       0.29      0.33      0.31       189\n",
            "weighted avg       0.77      0.86      0.81       189\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "dt_clr = DecisionTreeClassifier(max_depth=5)\n",
        "dt_clr.fit(X_train, y_train)\n",
        "y_pred = dt_clr.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARty48OSRBJ8"
      },
      "source": [
        "# Cross-validation on Random Forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmgwl3ZqRBJ8",
        "outputId": "f5028e64-5089-4c4a-a1c9-c05d07ea6383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.91534392 0.91534392 0.92021277 0.92021277 0.91489362]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "rf_clr = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "scores = cross_val_score(rf_clr, X_features, Y, cv=5)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzpciECWRBJ9",
        "outputId": "2082159c-54d8-4da1-bdce-61b43151c636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94       166\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.88       189\n",
            "   macro avg       0.29      0.33      0.31       189\n",
            "weighted avg       0.77      0.88      0.82       189\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clr = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "rf_clr.fit(X_train, y_train)\n",
        "y_pred = rf_clr.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkOnNKXoRBJ-"
      },
      "source": [
        "# 3.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oee9Sy91RBJ_"
      },
      "source": [
        ". The metrics for classification are precision, recall, accuracy, f1-score.\\\n",
        ". The decision tree accuracy is less than random forest accuracy.\\\n",
        ". Since the dataset is imbalanced, the f1 scores of negative(1) and neutral(2) classes are 0.\\\n",
        ". Among the two classifiers above, random forest classifier is the best sentiment classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download here: https://github.com/unt-iialab/info5731-spring2022/blob/main/assignments/assignment4-question3-data.zip. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfvMKJjIXS5G",
        "outputId": "1894da95-bdd0-41e1-8796-c704802fc85c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
              "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
              "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
              "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
              "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
              "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
              "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
              "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
              "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
              "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
              "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
              "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
              "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
              "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
              "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
              "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
              "       'SaleCondition', 'SalePrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the train dataset\n",
        "train_data = pd.read_csv(\"/content/gdrive/My Drive/assignment4-question3-data/train.csv\")\n",
        "\n",
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4jhClxbRBKC",
        "outputId": "c04677b5-4b01-4807-ef93-4ba3982bfda6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LotFrontage  259     17.74\n",
            "Alley  1369     93.77\n",
            "MasVnrType  8     0.55\n",
            "MasVnrArea  8     0.55\n",
            "BsmtQual  37     2.53\n",
            "BsmtCond  37     2.53\n",
            "BsmtExposure  38     2.6\n",
            "BsmtFinType1  37     2.53\n",
            "BsmtFinType2  38     2.6\n",
            "Electrical  1     0.07\n",
            "FireplaceQu  690     47.26\n",
            "GarageType  81     5.55\n",
            "GarageYrBlt  81     5.55\n",
            "GarageFinish  81     5.55\n",
            "GarageQual  81     5.55\n",
            "GarageCond  81     5.55\n",
            "PoolQC  1453     99.52\n",
            "Fence  1179     80.75\n",
            "MiscFeature  1406     96.3\n"
          ]
        }
      ],
      "source": [
        "# null values percentage\n",
        "for column in train_data.columns:\n",
        "    if train_data[column].isna().sum()/train_data.shape[0]*100 != 0:\n",
        "        print(column, \"\", train_data[column].isna().sum(), \"   \", round(train_data[column].isna().sum()/train_data.shape[0]*100, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SePpuk4nRBKC"
      },
      "outputs": [],
      "source": [
        "# dropping columns with higher null values % and columns that have year values.\n",
        "train_data = train_data.drop(['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'YearBuilt',\n",
        "                             'YearRemodAdd', 'GarageYrBlt', 'YrSold'], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET19PV4yRBKD",
        "outputId": "5d3af730-fd6a-4af6-cd53-75b3b8f65bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float64 LotFrontage  259     17.74\n",
            "object MasVnrType  8     0.55\n",
            "float64 MasVnrArea  8     0.55\n",
            "object BsmtQual  37     2.53\n",
            "object BsmtCond  37     2.53\n",
            "object BsmtExposure  38     2.6\n",
            "object BsmtFinType1  37     2.53\n",
            "object BsmtFinType2  38     2.6\n",
            "object Electrical  1     0.07\n",
            "object GarageType  81     5.55\n",
            "object GarageFinish  81     5.55\n",
            "object GarageQual  81     5.55\n",
            "object GarageCond  81     5.55\n"
          ]
        }
      ],
      "source": [
        "for column in train_data.columns:\n",
        "    if train_data[column].isna().sum()/train_data.shape[0]*100 != 0:\n",
        "        print((train_data[column]).dtype, column , \"\", train_data[column].isna().sum(), \"   \", round(train_data[column].isna().sum()/train_data.shape[0]*100, 2))\n",
        "#print(train_data.isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiSJ_8o4RBKE"
      },
      "outputs": [],
      "source": [
        "# replacing null values with mean, mode values of that column.\n",
        "for col in ['LotFrontage', 'MasVnrArea']:\n",
        "    train_data[col].fillna(train_data[col].mean(), inplace = True)\n",
        "    \n",
        "for col in ['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', \n",
        "            'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
        "    train_data[col].fillna(train_data[col].mode()[0], inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBUzlN5tRBKE"
      },
      "outputs": [],
      "source": [
        "for column in train_data.columns:\n",
        "    if train_data[column].isna().sum()/train_data.shape[0]*100 != 0:\n",
        "        print((train_data[column]).dtype, column , \"\", train_data[column].isna().sum(), \"   \", round(train_data[column].isna().sum()/train_data.shape[0]*100, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cicScPFPRBKF",
        "outputId": "c4187bff-ed6f-4901-eb65-81d8310aeaeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 72)\n",
            "(1460, 268)\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape)\n",
        "\n",
        "# categorical columns dummification \n",
        "train_data = pd.get_dummies(train_data)\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3vcCnPSRBKF"
      },
      "source": [
        "# Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niBAUXwHRBKF",
        "outputId": "eb9c5b12-f504-4520-cabc-fa66eee46996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 54720.020379664515\n",
            "R2 Score: 0.5664138888104355\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = train_data.drop(['SalePrice'], axis = 1)\n",
        "y = train_data['SalePrice']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_pred = lin_reg.predict(X_valid)\n",
        "\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_valid, y_pred)))\n",
        "print(\"R2 Score:\", r2_score(y_valid, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_O5e8GuRBKG"
      },
      "source": [
        "# Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idYLevk6RBKG",
        "outputId": "53710a0f-b3fa-4bf2-826c-ea8f50cd4483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 46456.33468816109\n",
            "R2 Score: 0.6874836488038527\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dtreg = DecisionTreeRegressor(max_depth=5)\n",
        "dtreg.fit(X_train, y_train)\n",
        "y_pred = dtreg.predict(X_valid)\n",
        "\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_valid, y_pred)))\n",
        "print(\"R2 Score:\", r2_score(y_valid, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVIO0BarRBKH"
      },
      "source": [
        "# Random forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmF57nIKRBKH",
        "outputId": "218ba8d6-6125-4943-c438-9f5d796aee01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 37255.72132814937\n",
            "R2 Score: 0.7990126083080934\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_reg = RandomForestRegressor(max_depth=5, random_state=0)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "y_pred = rf_reg.predict(X_valid)\n",
        "\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_valid, y_pred)))\n",
        "print(\"R2 Score:\", r2_score(y_valid, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TuGh-DwRBKI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z2xvHaURBKI",
        "outputId": "50d69809-ee01-4495-9e85-842b8271a701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object MSZoning  4     0.27\n",
            "float64 LotFrontage  227     15.56\n",
            "object Utilities  2     0.14\n",
            "object Exterior1st  1     0.07\n",
            "object Exterior2nd  1     0.07\n",
            "object MasVnrType  16     1.1\n",
            "float64 MasVnrArea  15     1.03\n",
            "object BsmtQual  44     3.02\n",
            "object BsmtCond  45     3.08\n",
            "object BsmtExposure  44     3.02\n",
            "object BsmtFinType1  42     2.88\n",
            "float64 BsmtFinSF1  1     0.07\n",
            "object BsmtFinType2  42     2.88\n",
            "float64 BsmtFinSF2  1     0.07\n",
            "float64 BsmtUnfSF  1     0.07\n",
            "float64 TotalBsmtSF  1     0.07\n",
            "float64 BsmtFullBath  2     0.14\n",
            "float64 BsmtHalfBath  2     0.14\n",
            "object KitchenQual  1     0.07\n",
            "object Functional  2     0.14\n",
            "object GarageType  76     5.21\n",
            "object GarageFinish  78     5.35\n",
            "float64 GarageCars  1     0.07\n",
            "float64 GarageArea  1     0.07\n",
            "object GarageQual  78     5.35\n",
            "object GarageCond  78     5.35\n",
            "object SaleType  1     0.07\n"
          ]
        }
      ],
      "source": [
        "test_data = pd.read_csv(\"/content/gdrive/My Drive/assignment4-question3-data/test.csv\")\n",
        "\n",
        "test_data = test_data.drop(['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'YearBuilt',\n",
        "                             'YearRemodAdd', 'GarageYrBlt', 'YrSold'], axis = 1)\n",
        "\n",
        "for column in test_data.columns:\n",
        "    if test_data[column].isna().sum()/test_data.shape[0]*100 != 0:\n",
        "        print((test_data[column]).dtype, column, \"\", test_data[column].isna().sum(), \"   \", round(test_data[column].isna().sum()/test_data.shape[0]*100, 2))\n",
        "#print(train_data.isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVTXYLrZRBKI"
      },
      "outputs": [],
      "source": [
        "# replacing null values with mean, mode values of that column.\n",
        "for col in ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
        "           'BsmtHalfBath', 'GarageCars', 'GarageArea']:\n",
        "    test_data[col].fillna(test_data[col].mean(), inplace = True)\n",
        "    \n",
        "for col in ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
        "           'BsmtFinType1', 'BsmtFinType2', 'KitchenQual', 'Functional', 'GarageType', 'GarageFinish', 'GarageQual',\n",
        "           'GarageCond', 'SaleType']:\n",
        "    test_data[col].fillna(test_data[col].mode()[0], inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaQ-3puERBKJ"
      },
      "outputs": [],
      "source": [
        "for column in test_data.columns:\n",
        "    if test_data[column].isna().sum()/test_data.shape[0]*100 != 0:\n",
        "        print((test_data[column]).dtype, column, \"\", test_data[column].isna().sum(), \"   \", round(test_data[column].isna().sum()/test_data.shape[0]*100, 2))\n",
        "#print(train_data.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klDDtSKXRBKJ",
        "outputId": "cb4a497f-1b15-4c24-829b-ab6aa3ea1364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1459, 71)\n",
            "(1459, 251)\n"
          ]
        }
      ],
      "source": [
        "print(test_data.shape)\n",
        "\n",
        "test_data = pd.get_dummies(test_data)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lUV6BZgRBKK",
        "outputId": "37ef6f55-794a-4d91-df91-66c1f8e4f3f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utilities_NoSeWa\n",
            "Condition2_RRAe\n",
            "Condition2_RRAn\n",
            "Condition2_RRNn\n",
            "HouseStyle_2.5Fin\n",
            "RoofMatl_ClyTile\n",
            "RoofMatl_Membran\n",
            "RoofMatl_Metal\n",
            "RoofMatl_Roll\n",
            "Exterior1st_ImStucc\n",
            "Exterior1st_Stone\n",
            "Exterior2nd_Other\n",
            "Heating_Floor\n",
            "Heating_OthW\n",
            "Electrical_Mix\n",
            "GarageQual_Ex\n"
          ]
        }
      ],
      "source": [
        "for col in train_data.columns:\n",
        "    if col not in test_data.columns and col != 'SalePrice':\n",
        "        print(col)\n",
        "        test_data[col] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egVPoZBrRBKK",
        "outputId": "f64371c8-2ad9-4137-f070-41329c0094cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1459, 267)\n"
          ]
        }
      ],
      "source": [
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHGTVSfiRBKL",
        "outputId": "f0de09c8-3d75-4574-8152-d037477d0c82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names must be in the same order as they were in fit.\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Among all the models, random forest regressor performs well\n",
        "# as the R2 score is better.\n",
        "y_pred = rf_reg.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wwU9toYRBKL",
        "outputId": "4d809177-78af-4942-a0bf-d47d10a3d786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([116524.52992537, 149149.14958385, 182709.17281549, ...,\n",
              "       149007.60848061, 108780.85592607, 226827.64341166])"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predictions for test data\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8WCBtcSRBKM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "INFO5731_Assignment_Four.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}