{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravilladivyaUNT/Divya_INFO5731_-Spring2022/blob/main/In_class_exercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtydfFGrNB0L"
      },
      "source": [
        "## The third In-class-exercise (02/08/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NspByZmvNB0P"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7x1iqW5NB0R"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XoBZkvS9NB0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "23d37937-f961-418c-dd63-83c649eb9865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nMy task is to perform sentimental analysis on text data. So, I have used IMDB website to extract movie review dataset. I have collected all the data required.  After collecting all the\\ndataset preprocessing techniques should be applied on dataset and then machine learning algorithm should be applied for sentimental \\nanalysis. I used selenium for web scraping. It retrieved the data of more than 1000 movie reviews from IMDB website. Python code that gain access to \\nIMDB website and extract meaningful data ie:Title of the review, review of the movies. All the collected data is loaded into pandas which has\\n[1100 rows x 2 columns]. I have imported below modules and packages:\\n1. !pip install selenium\\n2. from selenium.webdriver.common.by import By\\n3. from selenium.webdriver.support.ui import WebDriverWait as wait\\n4. from selenium import webdriver \\n5. !apt install chromium-chromedriver\\n6. !cp /usr/lib/chromium-browser/chromedriver /usr/bin\\n\\n\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "My task is to perform sentimental analysis on text data. So, I have used IMDB website to extract movie review dataset. I have collected all the data required.  After collecting all the\n",
        "dataset preprocessing techniques should be applied on dataset and then machine learning algorithm should be applied for sentimental \n",
        "analysis. I used selenium for web scraping. It retrieved the data of more than 1000 movie reviews from IMDB website. Python code that gain access to \n",
        "IMDB website and extract meaningful data ie:Title of the review, review of the movies. All the collected data is loaded into pandas which has\n",
        "[1100 rows x 2 columns]. I have imported below modules and packages:\n",
        "1. !pip install selenium\n",
        "2. from selenium.webdriver.common.by import By\n",
        "3. from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "4. from selenium import webdriver \n",
        "5. !apt install chromium-chromedriver\n",
        "6. !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs5orTuRNB0U"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YKt0c-2HNB0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00ff30f6-557f-4a0b-b745-de66caf63f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "\u001b[K     |████████████████████████████████| 958 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 43.9 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 55.0 MB/s \n",
            "\u001b[?25hCollecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 28.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.0 sniffio-1.2.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.8 wsproto-1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,468 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,564 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [783 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,825 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,004 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [935 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [816 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,247 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 14.9 MB in 4s (3,564 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 63 not upgraded.\n",
            "Need to get 95.3 MB of archives.\n",
            "After this operation, 327 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 97.0.4692.71-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 97.0.4692.71-0ubuntu0.18.04.1 [84.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 97.0.4692.71-0ubuntu0.18.04.1 [4,370 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 97.0.4692.71-0ubuntu0.18.04.1 [5,055 kB]\n",
            "Fetched 95.3 MB in 4s (23.9 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_97.0.4692.71-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "import requests, openpyxl\n",
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!apt-get update\n",
        "from bs4 import BeautifulSoup as bs\n",
        "!apt install chromium-chromedriver\n",
        "import urllib.request as req\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import pandas as pd\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "from selenium import webdriver \n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ],
      "metadata": {
        "id": "vBw4NqxlvdgI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "titles = [] \n",
        "reviews= []\n",
        "link = 'https://www.imdb.com/title/tt15097216/reviews?ref_=tt_ov_rt'\n",
        "d = webdriver.Chrome('chromedriver',options=options) #creating a driver path\n",
        "d.get(link)\n",
        "for num in range(43):         \n",
        "  d.find_element_by_class_name(\"ipl-load-more__button\").click() \n",
        "  time.sleep(5)\n",
        "  LTitle = d.find_elements(By.CLASS_NAME, \"title\") #Using Find_elements to get titles of the movie\n",
        "  LReviews = d.find_elements(By.CLASS_NAME, \"text\") #Using Find_elements to get reviews of the movie\n",
        "  \n",
        "for e, r in zip(LTitle, LReviews):            # appending all reviews and titles into the empty arrays\n",
        "      titles.append((e.text).replace('\\n',''))\n",
        "      reviews.append(r.text)\n",
        "      \n",
        "df = pd.DataFrame(list(zip(titles, reviews)), columns =['Title of the Review', 'Review of the movie'])\n",
        "print(\"Length of data frame is\",len(df))\n",
        "print(df)"
      ],
      "metadata": {
        "id": "d_sAEUNwvwKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eef217d-1f12-4c50-a6ad-42c57991d0fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1100\n",
            "                                    Title of the Review                                Review of the movie\n",
            "0                  \"It will be quite an uphill battle.\"                                                   \n",
            "1                                     Simply amazing...  \"Jai Bhim\" is a Crime - Drama movie in which w...\n",
            "2     Jai Bhim's subject is too extraordinary to be ...                                                   \n",
            "3     Captivating, well acted n thought provoking. N...  If Atticus Finch is the greatest movie hero, t...\n",
            "4                   Tamil Tragedy, Turmoil & Torture...  This extraordinary story will leave you aghast...\n",
            "...                                                 ...                                                ...\n",
            "1095                                           Jai Bhim  Jai Bhim is outstanding movie I watched ever, ...\n",
            "1096                                   Must watch movie  A very intense movie. Every character played w...\n",
            "1097                                         Poli movie  The movie was very good and all the played act...\n",
            "1098                                            Soulful  Jai Bhim !! Beautifully crafted masterpiece. A...\n",
            "1099                        Must watch for every Indian                                                   \n",
            "\n",
            "[1100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obhLfrQANB0W"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json as js\n",
        "\n",
        "with req.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as fileread:\n",
        "    page = fileread.read()\n",
        "    soup = bs(page)\n",
        "    print(soup.p.text)\n",
        "    with open('output.txt', 'w') as filewrite:\n",
        "        js.dump(soup.p.text, filewrite)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtjW97U06TiB",
        "outputId": "c22da1c7-0df7-45a9-8be7-ae9f8053b7e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"abstract\":\"Typically, every part in most coherent text has some plausible reason for its presence, some function that it performs to the overall semantics of the text. Rhetorical relations, e.g. contrast, cause, explanation, describe how the parts of a text are linked to each other. Knowledge about this so-called discourse structure has been applied successfully to several natural language processing tasks. This work studies the use of rhetorical relations for Information Retrieval (IR): Is there a correlation between certain rhetorical relations and retrieval performance? Can knowledge about a document's rhetorical relations be useful to IR? We present a language model modification that considers rhetorical relations when estimating the relevance of a document to a query. Empirical evaluation of different versions of our model on TREC settings shows that certain rhetorical relations can benefit retrieval effectiveness notably (>10% in mean average precision over a state-of-the-art baseline).\",\"arxivId\":\"1704.01599\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\",\"url\":\"https://www.semanticscholar.org/author/1784800\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\",\"url\":\"https://www.semanticscholar.org/author/145216927\"},{\"authorId\":\"2153424532\",\"name\":\"Wei Lu\",\"url\":\"https://www.semanticscholar.org/author/2153424532\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144144799\",\"name\":\"Puneet Mathur\"},{\"authorId\":\"39878379\",\"name\":\"R. Jain\"},{\"authorId\":\"2075390842\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"2852035\",\"name\":\"Vlad I. Morariu\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.18653/v1/2021.acl-short.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce9e010c5cb2323dfed3af687b12875f01c759bc\",\"title\":\"TIMERS: Document-level Temporal Relation Extraction\",\"url\":\"https://www.semanticscholar.org/paper/ce9e010c5cb2323dfed3af687b12875f01c759bc\",\"venue\":\"ACL/IJCNLP\",\"year\":2021},{\"arxivId\":\"2006.00572\",\"authors\":[{\"authorId\":\"8566053\",\"name\":\"Erfaneh Gharavi\"},{\"authorId\":\"2024809\",\"name\":\"H. Veisi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"213c505be2cc73343110fd6a41982f0ddaa2d0ee\",\"title\":\"Improve Document Embedding for Text Categorization Through Deep Siamese Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/213c505be2cc73343110fd6a41982f0ddaa2d0ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021071353\",\"name\":\"B. Galitsky\"}],\"doi\":\"10.1007/978-3-030-61641-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91d910139cddd7acd4858dd98ccef72cacdbb644\",\"title\":\"Chatbots for CRM and Dialogue Management\",\"url\":\"https://www.semanticscholar.org/paper/91d910139cddd7acd4858dd98ccef72cacdbb644\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144264304\",\"name\":\"Boris A. Galitsky\"},{\"authorId\":\"1755765\",\"name\":\"Dmitry Ilvovsky\"}],\"doi\":\"10.26615/978-954-452-056-4_044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2311b92150c7b10c43d9b59348cc2ccf93da9bf2\",\"title\":\"Discourse-Based Approach to Involvement of Background Knowledge for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2311b92150c7b10c43d9b59348cc2ccf93da9bf2\",\"venue\":\"RANLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8566053\",\"name\":\"Erfaneh Gharavi\"},{\"authorId\":\"83195228\",\"name\":\"R. Silwal\"},{\"authorId\":\"2134075\",\"name\":\"M. Gerber\"},{\"authorId\":\"2024809\",\"name\":\"H. Veisi\"}],\"doi\":\"10.1109/ICOSC.2019.8665662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31c0b55c8ba469874c4fa7b3fd8b70375b1e7421\",\"title\":\"Siamese Discourse Structure Recursive Neural Network for Semantic Representation\",\"url\":\"https://www.semanticscholar.org/paper/31c0b55c8ba469874c4fa7b3fd8b70375b1e7421\",\"venue\":\"2019 IEEE 13th International Conference on Semantic Computing (ICSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1162/coli_a_00360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"710e8c7fa63104ecaf5aee2b898c0c465f82b96d\",\"title\":\"Discourse in Multimedia: A Case Study in Extracting Geometry Knowledge from Textbooks\",\"url\":\"https://www.semanticscholar.org/paper/710e8c7fa63104ecaf5aee2b898c0c465f82b96d\",\"venue\":\"Computational Linguistics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144264304\",\"name\":\"Boris A. Galitsky\"}],\"doi\":\"10.1007/978-3-030-04299-8_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bb0bafea9a8e9ee177ddf6fa116d1b3b9ae9a89\",\"title\":\"Discourse-Level Dialogue Management\",\"url\":\"https://www.semanticscholar.org/paper/7bb0bafea9a8e9ee177ddf6fa116d1b3b9ae9a89\",\"venue\":\"Developing Enterprise Chatbots\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1162/COLI_a_00360\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3722832c69a6e6e42fc314ec3feb56e18b5b51f\",\"title\":\"Discourse in Multimedia: A Case Study in Extracting Geometry Knowledge from Textbooks\",\"url\":\"https://www.semanticscholar.org/paper/c3722832c69a6e6e42fc314ec3feb56e18b5b51f\",\"venue\":\"Computational Linguistics\",\"year\":2020},{\"arxivId\":\"1811.05546\",\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56e13ac67e383b80896436122cce5a34617a9513\",\"title\":\"Discourse in Multimedia: A Case Study in Information Extraction\",\"url\":\"https://www.semanticscholar.org/paper/56e13ac67e383b80896436122cce5a34617a9513\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413101320\",\"name\":\"Lin Chuan-An\"},{\"authorId\":\"2611607\",\"name\":\"Hen-Hsen Huang\"},{\"authorId\":\"8157332\",\"name\":\"Zi-Yuan Chen\"},{\"authorId\":\"153924342\",\"name\":\"Hsin-Hsi Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7d77615ace68f881a5db6db50b45cb0f8da465c\",\"title\":\"A Unified RvNN Framework for End-to-End Chinese Discourse Parsing\",\"url\":\"https://www.semanticscholar.org/paper/f7d77615ace68f881a5db6db50b45cb0f8da465c\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"143709239\",\"name\":\"A. Firsov\"}],\"doi\":\"10.1145/3077136.3080720\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19f11641dc8f1ede579ca4e7f212b96d2a8c607f\",\"title\":\"A Metric for Sentence Ordering Assessment Based on Topic-Comment Structure\",\"url\":\"https://www.semanticscholar.org/paper/19f11641dc8f1ede579ca4e7f212b96d2a8c607f\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2072910756\",\"name\":\"V\\u00edctor Flores\"},{\"authorId\":\"2098570488\",\"name\":\"Yahima Hadfeg\"},{\"authorId\":\"2385175\",\"name\":\"Claudio Meneses Villegas\"}],\"doi\":\"10.1007/978-3-319-60837-2_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ec8e675d1ff640e4828e174a54e2beaec3679e6\",\"title\":\"Generating Natural Language Explanations from Knowledge-Based Systems Results, Using Ontology and Discourses Patterns\",\"url\":\"https://www.semanticscholar.org/paper/3ec8e675d1ff640e4828e174a54e2beaec3679e6\",\"venue\":\"IJCRS\",\"year\":2017},{\"arxivId\":\"1703.03640\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"3018458\",\"name\":\"N. Hansen\"}],\"doi\":\"10.1016/j.cogsys.2017.03.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"478adb395044b5d9b4039b9a80963b151446cdab\",\"title\":\"A study of metrics of distance and correlation between ranked lists for compositionality detection\",\"url\":\"https://www.semanticscholar.org/paper/478adb395044b5d9b4039b9a80963b151446cdab\",\"venue\":\"Cognitive Systems Research\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"2027419668\",\"name\":\"J. Mothe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5af0f4536f8a98d7e42a40be3fd0e5e51c08d166\",\"title\":\"La structure th\\u00e8me-rh\\u00e8me pour l'ordonnancement de documents en recherche d'information\",\"url\":\"https://www.semanticscholar.org/paper/5af0f4536f8a98d7e42a40be3fd0e5e51c08d166\",\"venue\":\"Document Num\\u00e9rique\",\"year\":2017},{\"arxivId\":\"1709.03742\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ff7f47ef653603b6f65c128627c280ca1026dba\",\"title\":\"Dependencies: Formalising Semantic Catenae for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8ff7f47ef653603b6f65c128627c280ca1026dba\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b9d7421cec8448b0ca96d74cefab96c25d29a1c\",\"title\":\"Short text contextualization in information retrieval : application to tweet contextualization and automatic query expansion. (Contextualisation de textes courts pour la recherche d'information : application \\u00e0 la contextualisation de tweets et \\u00e0 l'expansion automatique de requ\\u00eates)\",\"url\":\"https://www.semanticscholar.org/paper/0b9d7421cec8448b0ca96d74cefab96c25d29a1c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"}],\"doi\":\"10.1109/RCIS.2016.7549352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c4c5d3c9ba58c7e0aadcca70c0771a662ca97dd\",\"title\":\"Document re-ranking based on topic-comment structure\",\"url\":\"https://www.semanticscholar.org/paper/1c4c5d3c9ba58c7e0aadcca70c0771a662ca97dd\",\"venue\":\"2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)\",\"year\":2016},{\"arxivId\":\"1608.00758\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1724314\",\"name\":\"Fabien Tarissan\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"8304471\",\"name\":\"Casper Petersen\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"}],\"doi\":\"10.1145/2970398.2970413\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e45b7dbe1f12ea0110fa5bb7609aa90b33c20d9\",\"title\":\"Exploiting the Bipartite Structure of Entity Grids for Document Coherence and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3e45b7dbe1f12ea0110fa5bb7609aa90b33c20d9\",\"venue\":\"ICTIR\",\"year\":2016},{\"arxivId\":\"1610.01327\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"},{\"authorId\":\"2153424616\",\"name\":\"Wei Lu\"},{\"authorId\":\"2145587478\",\"name\":\"Yong Huang\"}],\"doi\":\"10.1145/3006299.3006315\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8064f19f6f07e471a5ed84e3e862ab9b0763185a\",\"title\":\"A study of factuality, objectivity and relevance: three desiderata in large-scale information retrieval?\",\"url\":\"https://www.semanticscholar.org/paper/8064f19f6f07e471a5ed84e3e862ab9b0763185a\",\"venue\":\"BDCAT\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027419668\",\"name\":\"J. Mothe\"},{\"authorId\":\"3162238\",\"name\":\"Marion Moulinou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a73852122c71aad778993222766c6f4dd740fd6\",\"title\":\"Analyse des param\\u00e8tres de recherche d'information: Etude de l'influence des param\\u00e8tres sur les r\\u00e9sultats\",\"url\":\"https://www.semanticscholar.org/paper/8a73852122c71aad778993222766c6f4dd740fd6\",\"venue\":\"EGC\",\"year\":2015},{\"arxivId\":\"1507.08234\",\"authors\":[{\"authorId\":\"8304471\",\"name\":\"Casper Petersen\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"}],\"doi\":\"10.1145/2808194.2809458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9cb0f457cc8ff9c56b92b96e2e14565feb56552\",\"title\":\"Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR\",\"url\":\"https://www.semanticscholar.org/paper/e9cb0f457cc8ff9c56b92b96e2e14565feb56552\",\"venue\":\"ICTIR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2762285\",\"name\":\"Jos\\u00e9 M. Chenlo\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"2356644\",\"name\":\"D. Losada\"}],\"doi\":\"10.1016/j.datak.2014.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6007af381e860f920fc05401fe826c67c6f2b18a\",\"title\":\"Rhetorical Structure Theory for polarity estimation: An experimental study\",\"url\":\"https://www.semanticscholar.org/paper/6007af381e860f920fc05401fe826c67c6f2b18a\",\"venue\":\"Data Knowl. Eng.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"133998176\",\"name\":\"Gonz\\u00e1lez Chenlo\"},{\"authorId\":\"2056448538\",\"name\":\"Josep Manuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd2426c0f4fd14a2a061662a2074b52bcd3f06bb\",\"title\":\"Exploiting multiple sources of evidence for opinion search in the web\",\"url\":\"https://www.semanticscholar.org/paper/bd2426c0f4fd14a2a061662a2074b52bcd3f06bb\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14201699\",\"name\":\"Sungbin Choi\"},{\"authorId\":\"4273555\",\"name\":\"Jinwook Choi\"},{\"authorId\":\"34786903\",\"name\":\"Sooyoung Yoo\"},{\"authorId\":\"2108878965\",\"name\":\"Heechun Kim\"},{\"authorId\":\"2110076700\",\"name\":\"Youngho Lee\"}],\"doi\":\"10.1016/j.jbi.2013.08.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7181bd11fa61899b3ccd4c7f527de0eb6244913\",\"title\":\"Semantic concept-enriched dependence model for medical information retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c7181bd11fa61899b3ccd4c7f527de0eb6244913\",\"venue\":\"J. Biomed. Informatics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48969078\",\"name\":\"W. Drijfhout\"},{\"authorId\":\"71595481\",\"name\":\"O. Jundt\"},{\"authorId\":\"2911513\",\"name\":\"L. Wevers\"},{\"authorId\":\"1691929\",\"name\":\"D. Hiemstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ca1c847a200f46c969261d3686f7be136c7bef\",\"title\":\"Traitor: Associating Concepts using the World Wide Web\",\"url\":\"https://www.semanticscholar.org/paper/10ca1c847a200f46c969261d3686f7be136c7bef\",\"venue\":\"DIR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127495\",\"name\":\"F. Alarfaj\"},{\"authorId\":\"2993548\",\"name\":\"Udo Kruschwitz\"},{\"authorId\":\"144251978\",\"name\":\"C. Fox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3aa86dcc5c2b83e7a39481dd729f07e9eb90c87c\",\"title\":\"An Adaptive Window-Size Approach for Expert-Finding\",\"url\":\"https://www.semanticscholar.org/paper/3aa86dcc5c2b83e7a39481dd729f07e9eb90c87c\",\"venue\":\"DIR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34805599\",\"name\":\"K. Englmeier\"},{\"authorId\":\"36946798\",\"name\":\"J. Atkinson\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"1721235\",\"name\":\"F. Murtagh\"},{\"authorId\":\"145433856\",\"name\":\"Javier Pereira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c844ff5f73186762d70cfa0247ffd90ac582860\",\"title\":\"Open Archive TOULOUSE Archive Ouverte (OATAO)\",\"url\":\"https://www.semanticscholar.org/paper/3c844ff5f73186762d70cfa0247ffd90ac582860\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2762285\",\"name\":\"Jos\\u00e9 M. Chenlo\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"2356644\",\"name\":\"D. Losada\"}],\"doi\":\"10.1007/978-3-642-38824-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5550303aab415c066964738e32bc7076209ba4ad\",\"title\":\"Sentiment-Based Ranking of Blog Posts Using Rhetorical Structure Theory\",\"url\":\"https://www.semanticscholar.org/paper/5550303aab415c066964738e32bc7076209ba4ad\",\"venue\":\"NLDB\",\"year\":2013}],\"corpusId\":7087061,\"doi\":\"10.1145/2348283.2348407\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"isOpenAccess\":true,\"isPublisherLicensed\":true,\"is_open_access\":true,\"is_publisher_licensed\":true,\"numCitedBy\":28,\"numCiting\":40,\"paperId\":\"4c64daac9dda2920752e9a2b0333abe3e02f4beb\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144847871\",\"name\":\"W. Mann\"},{\"authorId\":\"20082155\",\"name\":\"S. Thompson\"}],\"doi\":\"10.1515/text.1.1988.8.3.243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af5100605a3b6bfd0adf9a30e69a47d1b98340ba\",\"title\":\"Rhetorical Structure Theory: Toward a functional theory of text organization\",\"url\":\"https://www.semanticscholar.org/paper/af5100605a3b6bfd0adf9a30e69a47d1b98340ba\",\"venue\":\"\",\"year\":1988},{\"arxivId\":\"1302.6782\",\"authors\":[{\"authorId\":\"1406721516\",\"name\":\"Adriano Azevedo-Filho\"},{\"authorId\":\"2932960\",\"name\":\"Ross D. Shachter\"}],\"doi\":\"10.1016/B978-1-55860-332-5.50009-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d7a296a0b0210be84934120396a41b7f7b2c25f\",\"title\":\"Laplace's Method Approximations for Probabilistic Inference in Belief Networks with Continuous Variables\",\"url\":\"https://www.semanticscholar.org/paper/7d7a296a0b0210be84934120396a41b7f7b2c25f\",\"venue\":\"UAI\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34938639\",\"name\":\"W. Gale\"},{\"authorId\":\"3215185\",\"name\":\"G. Sampson\"}],\"doi\":\"10.1080/09296179508590051\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cddeb5149f4de157d4daeb609a8b1432a8126e7b\",\"title\":\"Good-Turing Frequency Estimation Without Tears\",\"url\":\"https://www.semanticscholar.org/paper/cddeb5149f4de157d4daeb609a8b1432a8126e7b\",\"venue\":\"J. Quant. Linguistics\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749837\",\"name\":\"Eugene Charniak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d5e3fa888bee872b7adb7fa810089aa8ab1d58\",\"title\":\"A Maximum-Entropy-Inspired Parser\",\"url\":\"https://www.semanticscholar.org/paper/76d5e3fa888bee872b7adb7fa810089aa8ab1d58\",\"venue\":\"ANLP\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793218\",\"name\":\"D. Gildea\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.3115/1075218.1075283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c274b8aac56e49e65a3827c570b2496b14429166\",\"title\":\"Automatic Labeling of Semantic Roles\",\"url\":\"https://www.semanticscholar.org/paper/c274b8aac56e49e65a3827c570b2496b14429166\",\"venue\":\"ACL\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12303693\",\"name\":\"Lynn Carlson\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"},{\"authorId\":\"7424872\",\"name\":\"Mary Ellen Okurovsky\"}],\"doi\":\"10.3115/1118078.1118083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07a78850c0c2ff11acf21fccca40bfcb79da282b\",\"title\":\"Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory\",\"url\":\"https://www.semanticscholar.org/paper/07a78850c0c2ff11acf21fccca40bfcb79da282b\",\"venue\":\"SIGDIAL Workshop\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"2352980\",\"name\":\"T. Rath\"},{\"authorId\":\"2709427\",\"name\":\"F. Feng\"}],\"doi\":\"10.1145/383952.384005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67cb24c172b66b2d14f066a1f02ce57a22a075a1\",\"title\":\"Modeling score distributions for combining the outputs of search engines\",\"url\":\"https://www.semanticscholar.org/paper/67cb24c172b66b2d14f066a1f02ce57a22a075a1\",\"venue\":\"SIGIR '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2480901\",\"name\":\"Simone Teufel\"},{\"authorId\":\"2085030\",\"name\":\"M. Moens\"}],\"doi\":\"10.1162/089120102762671936\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54eafbf7621337724c6591cc13e604986243293a\",\"title\":\"Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status\",\"url\":\"https://www.semanticscholar.org/paper/54eafbf7621337724c6591cc13e604986243293a\",\"venue\":\"Computational Linguistics\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2768186\",\"name\":\"K. J\\u00e4rvelin\"},{\"authorId\":\"2732839\",\"name\":\"Jaana Kek\\u00e4l\\u00e4inen\"}],\"doi\":\"10.1145/582415.582418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8490234d79b47e459824dcf87c1e288211a3c964\",\"title\":\"Cumulated gain-based evaluation of IR techniques\",\"url\":\"https://www.semanticscholar.org/paper/8490234d79b47e459824dcf87c1e288211a3c964\",\"venue\":\"TOIS\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912454\",\"name\":\"C. Fillmore\"},{\"authorId\":\"1749194\",\"name\":\"Collin F. Baker\"},{\"authorId\":\"153515478\",\"name\":\"Hiroaki Sato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87834ded1d151355d2028dc6efb26fcaa48ab9fc\",\"title\":\"The FrameNet Database and Software Tools\",\"url\":\"https://www.semanticscholar.org/paper/87834ded1d151355d2028dc6efb26fcaa48ab9fc\",\"venue\":\"LREC\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736467\",\"name\":\"ChengXiang Zhai\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":\"10.1145/564376.564387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"decf799682a402b9ee50b9d6c0267f6c545a7031\",\"title\":\"Two-stage language models for information retrieval\",\"url\":\"https://www.semanticscholar.org/paper/decf799682a402b9ee50b9d6c0267f6c545a7031\",\"venue\":\"SIGIR '02\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2489901\",\"name\":\"Paul R. Kingsbury\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc090a68e45e0e6337136777d21c87b76a90ae72\",\"title\":\"From TreeBank to PropBank\",\"url\":\"https://www.semanticscholar.org/paper/fc090a68e45e0e6337136777d21c87b76a90ae72\",\"venue\":\"LREC\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"}],\"doi\":\"10.3115/1073445.1073475\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b3858c0c31c6f0826c891a42367671f6e76d46c\",\"title\":\"Sentence Level Discourse Parsing using Syntactic and Lexical Information\",\"url\":\"https://www.semanticscholar.org/paper/0b3858c0c31c6f0826c891a42367671f6e76d46c\",\"venue\":\"NAACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":\"10.1007/978-94-017-0171-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b71ead55fd6520dd4604de66cbb732bc2b7a6070\",\"title\":\"Language Modeling for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b71ead55fd6520dd4604de66cbb732bc2b7a6070\",\"venue\":\"The Springer International Series on Information Retrieval\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12294213\",\"name\":\"Jorge Luis Morato Lara\"},{\"authorId\":\"3028529\",\"name\":\"J. Morillo\"},{\"authorId\":\"1805316\",\"name\":\"Gonzalo G\\u00e9nova\"},{\"authorId\":\"31513219\",\"name\":\"J. Moreiro\"}],\"doi\":\"10.1016/S0306-4573(02)00081-X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb38a830255783ad3f0824d15f178dd03e5e2be2\",\"title\":\"Experiments in discourse analysis impact on information classification and retrieval algorithms\",\"url\":\"https://www.semanticscholar.org/paper/cb38a830255783ad3f0824d15f178dd03e5e2be2\",\"venue\":\"Inf. Process. Manag.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144009691\",\"name\":\"C. Buckley\"},{\"authorId\":\"1746656\",\"name\":\"E. Voorhees\"}],\"doi\":\"10.1145/1008992.1009000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6878cdc5b632e018f827a9d1520e7353d8502d25\",\"title\":\"Retrieval evaluation with incomplete information\",\"url\":\"https://www.semanticscholar.org/paper/6878cdc5b632e018f827a9d1520e7353d8502d25\",\"venue\":\"SIGIR '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119266345\",\"name\":\"D. Y. Wang\"},{\"authorId\":\"1752375\",\"name\":\"R. Luk\"},{\"authorId\":\"1784988\",\"name\":\"Kam-Fai Wong\"},{\"authorId\":\"145219946\",\"name\":\"K. Kwok\"}],\"doi\":\"10.1007/11765448_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6dcfcc8c5486859d78e317896abad0c4314442c\",\"title\":\"An Information Retrieval Approach Based on Discourse Type\",\"url\":\"https://www.semanticscholar.org/paper/e6dcfcc8c5486859d78e317896abad0c4314442c\",\"venue\":\"NLDB\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118254437\",\"name\":\"Mingyu Sun\"},{\"authorId\":\"1707259\",\"name\":\"J. Chai\"}],\"doi\":\"10.1016/j.knosys.2007.04.005\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"525867ebf15c535305f18eeb12b41b5d71168abf\",\"title\":\"Discourse processing for context question answering based on linguistic knowledge\",\"url\":\"https://www.semanticscholar.org/paper/525867ebf15c535305f18eeb12b41b5d71168abf\",\"venue\":\"Knowl. Based Syst.\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736049\",\"name\":\"B. Webber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"31793f9f959ac175632407ab0d9b7bda0e32f6f3\",\"title\":\"Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2\",\"url\":\"https://www.semanticscholar.org/paper/31793f9f959ac175632407ab0d9b7bda0e32f6f3\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2800288\",\"name\":\"David duVerle\"},{\"authorId\":\"2356111\",\"name\":\"H. Prendinger\"}],\"doi\":\"10.3115/1690219.1690239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cc84d84ad87b9a1f6496fb4acbbc758a9be6345\",\"title\":\"A Novel Discourse Parser Based on Support Vector Machine Classification\",\"url\":\"https://www.semanticscholar.org/paper/7cc84d84ad87b9a1f6496fb4acbbc758a9be6345\",\"venue\":\"ACL\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059584\",\"name\":\"Swapna Somasundaran\"},{\"authorId\":\"1686834\",\"name\":\"Galileo Namata\"},{\"authorId\":\"144120827\",\"name\":\"J. Wiebe\"},{\"authorId\":\"1746034\",\"name\":\"L. Getoor\"}],\"doi\":\"10.3115/1699510.1699533\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bd67cc94aa20fec80b205ee75517a4f194adc9c\",\"title\":\"Supervised and Unsupervised Methods in Employing Discourse Relations for Improving Opinion Polarity Classification\",\"url\":\"https://www.semanticscholar.org/paper/9bd67cc94aa20fec80b205ee75517a4f194adc9c\",\"venue\":\"EMNLP\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756567\",\"name\":\"L. Yu\"},{\"authorId\":\"1681512\",\"name\":\"Chung-Hsien Wu\"},{\"authorId\":\"3008622\",\"name\":\"Fong-Lin Jang\"}],\"doi\":\"10.1016/j.artint.2008.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfcb90cda0999a56a6d13bcac84f12adf0d2436\",\"title\":\"Psychiatric document retrieval using a discourse-aware model\",\"url\":\"https://www.semanticscholar.org/paper/cbfcb90cda0999a56a6d13bcac84f12adf0d2436\",\"venue\":\"Artif. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2160529\",\"name\":\"Daniel Tunkelang\"},{\"authorId\":\"1701298\",\"name\":\"M. Thelwall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d07576c370cc6ef48f9268714b4fd1c75b226ef5\",\"title\":\"Synthesis Lectures on Information Concepts, Retrieval, and Services\",\"url\":\"https://www.semanticscholar.org/paper/d07576c370cc6ef48f9268714b4fd1c75b226ef5\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689089\",\"name\":\"M. Smucker\"},{\"authorId\":\"144890574\",\"name\":\"James Allan\"},{\"authorId\":\"1750995\",\"name\":\"Ben Carterette\"}],\"doi\":\"10.1145/1571941.1572050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e38cde98f2e2012ee848bab4a3c964624783be7d\",\"title\":\"Agreement among statistical significance tests for information retrieval evaluation at varying sample sizes\",\"url\":\"https://www.semanticscholar.org/paper/e38cde98f2e2012ee848bab4a3c964624783be7d\",\"venue\":\"SIGIR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39055225\",\"name\":\"Jun Wang\"},{\"authorId\":\"39522749\",\"name\":\"Jianhan Zhu\"}],\"doi\":\"10.1145/1835449.1835489\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b6e6f0187f2cd44eeca1b80da464562357b20a\",\"title\":\"On statistical analysis and optimization of information retrieval effectiveness metrics\",\"url\":\"https://www.semanticscholar.org/paper/34b6e6f0187f2cd44eeca1b80da464562357b20a\",\"venue\":\"SIGIR\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50649676\",\"name\":\"J. Clarke\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1162/coli_a_00004\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"6c95908d08323c5acfc5bfdf7399f31563ade4f5\",\"title\":\"Discourse Constraints for Document Compression\",\"url\":\"https://www.semanticscholar.org/paper/6c95908d08323c5acfc5bfdf7399f31563ade4f5\",\"venue\":\"CL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767336\",\"name\":\"Annie Louis\"},{\"authorId\":\"1714374\",\"name\":\"A. Joshi\"},{\"authorId\":\"3115414\",\"name\":\"A. Nenkova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b88876344be6d9a8172f72bc0a836994f6b6f719\",\"title\":\"Discourse indicators for content selection in summarization\",\"url\":\"https://www.semanticscholar.org/paper/b88876344be6d9a8172f72bc0a836994f6b6f719\",\"venue\":\"SIGDIAL Conference\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9106864\",\"name\":\"Nipun Suwandaratna\"},{\"authorId\":\"47051364\",\"name\":\"Udayangi Perera\"}],\"doi\":\"10.1109/ICIAFS.2010.5715646\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c43f79ab60afc1e2bc3859365c120eb11bd0bbd7\",\"title\":\"Discourse marker based topic identification and search results refining\",\"url\":\"https://www.semanticscholar.org/paper/c43f79ab60afc1e2bc3859365c120eb11bd0bbd7\",\"venue\":\"2010 Fifth International Conference on Information and Automation for Sustainability\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1815447\",\"name\":\"Michael Bendersky\"},{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1891854\",\"name\":\"Y. Diao\"}],\"doi\":\"10.1145/1935826.1935849\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08c34883743406f05a10c54c802373997c706ce7\",\"title\":\"Quality-biased ranking of web documents\",\"url\":\"https://www.semanticscholar.org/paper/08c34883743406f05a10c54c802373997c706ce7\",\"venue\":\"WSDM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893187\",\"name\":\"Eyal Krikon\"},{\"authorId\":\"1779654\",\"name\":\"Oren Kurland\"}],\"doi\":\"10.1007/s10791-011-9168-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"278f55438b8fa2eb3cea6a120d48ea1f8b8b07f9\",\"title\":\"A study of the integration of passage-, document-, and cluster-based information for re-ranking search results\",\"url\":\"https://www.semanticscholar.org/paper/278f55438b8fa2eb3cea6a120d48ea1f8b8b07f9\",\"venue\":\"Information Retrieval\",\"year\":2011},{\"arxivId\":\"1004.5168\",\"authors\":[{\"authorId\":\"3114123\",\"name\":\"G. Cormack\"},{\"authorId\":\"1689089\",\"name\":\"M. Smucker\"},{\"authorId\":\"1751287\",\"name\":\"C. Clarke\"}],\"doi\":\"10.1007/s10791-011-9162-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38612e346fdf3158c32c16058f7e8820a8f0325e\",\"title\":\"Efficient and effective spam filtering and re-ranking for large web datasets\",\"url\":\"https://www.semanticscholar.org/paper/38612e346fdf3158c32c16058f7e8820a8f0325e\",\"venue\":\"Information Retrieval\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2325985\",\"name\":\"Michael Auli\"},{\"authorId\":\"144871732\",\"name\":\"Adam Lopez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"889b2925ae0966585b8da6f678526bbdd99da592\",\"title\":\"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/889b2925ae0966585b8da6f678526bbdd99da592\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801153\",\"name\":\"Bas Heerschop\"},{\"authorId\":\"2373094\",\"name\":\"F. Goossen\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"1729599\",\"name\":\"F. Frasincar\"},{\"authorId\":\"1678244\",\"name\":\"U. Kaymak\"},{\"authorId\":\"144097974\",\"name\":\"F. D. Jong\"}],\"doi\":\"10.1145/2063576.2063730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ba847377b1667add27eb9663aa847b53c59f9aa\",\"title\":\"Polarity analysis of texts using discourse structure\",\"url\":\"https://www.semanticscholar.org/paper/9ba847377b1667add27eb9663aa847b53c59f9aa\",\"venue\":\"CIKM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2718039\",\"name\":\"Christos Christodoulopoulos\"},{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"},{\"authorId\":\"145332819\",\"name\":\"Mark Steedman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6b2694d5606a0bbab63c4c470b20f1b754df9ff\",\"title\":\"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL\",\"url\":\"https://www.semanticscholar.org/paper/a6b2694d5606a0bbab63c4c470b20f1b754df9ff\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2152716490\",\"name\":\"Li Wang\"},{\"authorId\":\"5571580\",\"name\":\"Marco Lui\"},{\"authorId\":\"1736741380\",\"name\":\"Su Nam Kim\"},{\"authorId\":\"1720988\",\"name\":\"Joakim Nivre\"},{\"authorId\":\"145465286\",\"name\":\"Timothy Baldwin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d471854ae1705a5e4f6df60ec8fb602c6e88b673\",\"title\":\"Predicting Thread Discourse Structure over Technical Web Forums\",\"url\":\"https://www.semanticscholar.org/paper/d471854ae1705a5e4f6df60ec8fb602c6e88b673\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701219\",\"name\":\"Sucheta Ghosh\"},{\"authorId\":\"145341661\",\"name\":\"Richard Johansson\"},{\"authorId\":\"1719162\",\"name\":\"G. Riccardi\"},{\"authorId\":\"1809243\",\"name\":\"Sara Tonelli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2b168dbaa57736b31891451163a5c5582d84324\",\"title\":\"Shallow Discourse Parsing with Conditional Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/e2b168dbaa57736b31891451163a5c5582d84324\",\"venue\":\"IJCNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2204295\",\"name\":\"Lanjun Zhou\"},{\"authorId\":\"1707937\",\"name\":\"Binyang Li\"},{\"authorId\":\"145816335\",\"name\":\"Wei Gao\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"1784988\",\"name\":\"Kam-Fai Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5cb9f31922d4381a8b326b9cd9cbdacf744907c\",\"title\":\"Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities\",\"url\":\"https://www.semanticscholar.org/paper/e5cb9f31922d4381a8b326b9cd9cbdacf744907c\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36717818\",\"name\":\"A. Davison\"}],\"doi\":\"10.1007/978-1-4614-6170-8_100159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1be08088b4ca2a3d214cbbb325fbde30c334a77e\",\"title\":\"Statistical Models\",\"url\":\"https://www.semanticscholar.org/paper/1be08088b4ca2a3d214cbbb325fbde30c334a77e\",\"venue\":\"Encyclopedia of Social Network Analysis and Mining\",\"year\":2014}],\"s2FieldsOfStudy\":[{\"category\":\"Computer Science\",\"source\":\"external\"}],\"title\":\"Rhetorical relations for information retrieval\",\"topics\":[{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Linker (computing)\",\"topicId\":\"25565\",\"url\":\"https://www.semanticscholar.org/topic/25565\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"}],\"url\":\"https://www.semanticscholar.org/paper/4c64daac9dda2920752e9a2b0333abe3e02f4beb\",\"venue\":\"SIGIR '12\",\"year\":2012}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPC-X6A2NB0X"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}