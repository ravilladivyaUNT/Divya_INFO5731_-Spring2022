{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravilladivyaUNT/Divya_INFO5731_-Spring2022/blob/main/In_class_exercise_03_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzBdY473bkgf"
      },
      "source": [
        "## The third In-class-exercise (2/22/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFdsU-W1bkgh"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJz7cMkgbkgi"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YYeXsSWibkgj"
      },
      "outputs": [],
      "source": [
        "# Text classification can be used in spam identification.  \n",
        "# Most email services filter spam emails based on a number of rules or factors, such as the sender’s email address, malicious hyperlinks, \n",
        "# suspicious phrases, and more. But there’s no single definition of spam, and some unwanted emails can still reach users. Text classification \n",
        "# will make for an efficient spam detection. Spam detection is based on the assumption that its content differs from that of a legitimate email\n",
        "# in ways that can be quantified. A content of a typical spam email, which advertises attractive products and services can be characterized by \n",
        "# several statically features such as particular words frequency, special characters frequency, digits or alphabet frequency. Typical words such as\n",
        "# winner, dollar, award, cash prize, top job opportunities, earn more, beneficiary, good news, claim, high salary and payment attract users and \n",
        "# increase the chance that spam will be opened. These words can be used as features in the text classification process. \n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeDu4RZrbkgl"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cEbdWqvJbkgl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "\n",
        "DATA_DIR = 'enron1'\n",
        "target_names = ['ham', 'spam']\n",
        "def get_data(DATA_DIR):\n",
        "  subfolders = ['enron%d' % i for i in range(1,7)]\n",
        "  data = []\n",
        "  target = []\n",
        "  for subfolder in subfolders:\n",
        "   \n",
        "    spam_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'spam'))\n",
        "    for spam_file in spam_files:\n",
        "      with open(os.path.join(DATA_DIR, subfolder, 'spam', spam_file), encoding=\"latin-1\") as f:\n",
        "        data.append(f.read())\n",
        "        target.append(1)\n",
        "    \n",
        "    ham_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'ham'))\n",
        "    for ham_file in ham_files:\n",
        "      with open(os.path.join(DATA_DIR, subfolder, 'ham', ham_file), encoding=\"latin-1\") as f:\n",
        "        data.append(f.read())\n",
        "        target.append(0)\n",
        "  return data, target\n",
        "\n",
        "class SpamDetector(object):\n",
        "    def clean(self, s):\n",
        "        translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "        return s.translate(translator)\n",
        "    def tokenize(self, text):\n",
        "        text = self.clean(text).lower()\n",
        "        return re.split(\"\\W+\", text)\n",
        "    def get_word_counts(self, words):\n",
        "        word_counts = {}\n",
        "        for word in words:\n",
        "            word_counts[word] = word_counts.get(word, 0.0) + 1.0\n",
        "        return word_counts\n",
        "\n",
        "def fit(self, X, Y):\n",
        "    self.num_messages = {}\n",
        "    self.log_class_priors = {}\n",
        "    self.word_counts = {}\n",
        "    self.vocab = set()\n",
        "    n = len(X)\n",
        "    self.num_messages['spam'] = sum(1 for label in Y if label == 1)\n",
        "    self.num_messages['ham'] = sum(1 for label in Y if label == 0)\n",
        "    self.log_class_priors['spam'] = math.log(self.num_messages['spam'] / n)\n",
        "    self.log_class_priors['ham'] = math.log(self.num_messages['ham'] / n)\n",
        "    self.word_counts['spam'] = {}\n",
        "    self.word_counts['ham'] = {}\n",
        "    for x, y in zip(X, Y):\n",
        "        c = 'spam' if y == 1 else 'ham'\n",
        "        counts = self.get_word_counts(self.tokenize(x))\n",
        "        for word, count in counts.items():\n",
        "            if word not in self.vocab:\n",
        "                self.vocab.add(word)\n",
        "            if word not in self.word_counts[c]:\n",
        "                self.word_counts[c][word] = 0.0\n",
        "            self.word_counts[c][word] += count\n",
        "\n",
        "def predict(self, X):\n",
        "    result = []\n",
        "    for x in X:\n",
        "        counts = self.get_word_counts(self.tokenize(x))\n",
        "        spam_score = 0\n",
        "        ham_score = 0\n",
        "        for word, _ in counts.items():\n",
        "            if word not in self.vocab: continue\n",
        "            \n",
        "            log_w_given_spam = math.log( (self.word_counts['spam'].get(word, 0.0) + 1) / (self.num_messages['spam'] + len(self.vocab)) )\n",
        "            log_w_given_ham = math.log( (self.word_counts['ham'].get(word, 0.0) + 1) / (self.num_messages['ham'] + len(self.vocab)) )\n",
        "            spam_score += log_w_given_spam\n",
        "            ham_score += log_w_given_ham\n",
        "        spam_score += self.log_class_priors['spam']\n",
        "        ham_score += self.log_class_priors['ham']\n",
        "        if spam_score > ham_score:\n",
        "            result.append(1)\n",
        "        else:\n",
        "            result.append(0)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQkJ6fZlbkgm"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpSnbIF4bkgm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_03_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}